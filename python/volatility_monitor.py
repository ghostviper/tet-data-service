"""
Volatility Monitor for TET Framework
å¸ç§æ³¢åŠ¨æ€§ç›‘æ§è„šæœ¬ - è®¡ç®—ATRå’ŒIOæŒ‡æ ‡ï¼Œåˆ©ç”¨Redisæ•°æ®å­˜å‚¨
"""

import asyncio
import json
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import sys
import os
import time
from asyncio import Semaphore
from io import StringIO
import math

# Add project root and core to Python path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'core'))

from core.data_processor import CryptoDataProcessor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class VolatilityAnalyzer:
    """æ³¢åŠ¨æ€§åˆ†æå™¨ - è®¡ç®—ATRå’ŒIOæŒ‡æ ‡"""

    @staticmethod
    def calculate_true_range(high: pd.Series, low: pd.Series, close_prev: pd.Series) -> pd.Series:
        """è®¡ç®—çœŸå®æ³¢å¹… True Range"""
        # TR = max(High - Low, abs(High - Close_prev), abs(Low - Close_prev))
        hl_diff = high - low
        hc_diff = np.abs(high - close_prev)
        lc_diff = np.abs(low - close_prev)

        true_range = np.maximum(hl_diff, np.maximum(hc_diff, lc_diff))
        return pd.Series(true_range, index=high.index)

    @staticmethod
    def calculate_atr(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—å¹³å‡çœŸå®æ³¢å¹… ATR"""
        # è®¡ç®—å‰ä¸€æ—¥æ”¶ç›˜ä»·
        close_prev = close.shift(1)

        # è®¡ç®—çœŸå®æ³¢å¹…
        true_range = VolatilityAnalyzer.calculate_true_range(high, low, close_prev)

        # è®¡ç®—ATRï¼ˆä½¿ç”¨EMAå¹³æ»‘ï¼‰
        atr = true_range.ewm(span=period, adjust=False).mean()

        return atr

    @staticmethod
    def calculate_atr_percentage(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14) -> pd.Series:
        """è®¡ç®—ATRç™¾åˆ†æ¯”"""
        atr = VolatilityAnalyzer.calculate_atr(high, low, close, period)
        atr_percentage = (atr / close) * 100
        return atr_percentage

    @staticmethod
    def calculate_price_change(close: pd.Series, period: int = 1) -> pd.Series:
        """è®¡ç®—ä»·æ ¼æ¶¨è·Œå¹… (IO - In/Out)"""
        price_change = ((close - close.shift(period)) / close.shift(period)) * 100
        return price_change

    def calculate_volatility_metrics(self, df: pd.DataFrame) -> Dict:
        """è®¡ç®—å®Œæ•´çš„æ³¢åŠ¨æ€§æŒ‡æ ‡"""
        if len(df) < 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
            return None

        # è‡ªåŠ¨æ£€æµ‹æ•°æ®æ—¶é—´å‘¨æœŸ
        timeframe_minutes = self._detect_data_timeframe(df)
        logger.debug(f"æ£€æµ‹åˆ°æ•°æ®å‘¨æœŸ: {timeframe_minutes}åˆ†é’Ÿ")

        # æ ¹æ®æ£€æµ‹åˆ°çš„å‘¨æœŸè®¡ç®—å„åˆ†æå‘¨æœŸ
        periods = self._calculate_periods_for_timeframe(timeframe_minutes)

        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æ
        min_required_data = max(periods.values()) * 2
        if len(df) < min_required_data:
            logger.warning(f"æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘{min_required_data}æ¡æ•°æ®ï¼Œå½“å‰æœ‰{len(df)}æ¡")
            return None

        high = df['high']
        low = df['low']
        close = df['close']

        # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„å‘¨æœŸ
        atr_periods = periods

        # è®¡ç®—ATRæŒ‡æ ‡
        atr_metrics = {}
        for period_name, period_candles in atr_periods.items():
            if len(df) >= period_candles * 2:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
                atr = VolatilityAnalyzer.calculate_atr(high, low, close, period_candles)
                atr_pct = VolatilityAnalyzer.calculate_atr_percentage(high, low, close, period_candles)

                atr_metrics[f'atr_{period_name}'] = atr.iloc[-1] if not atr.empty else 0
                atr_metrics[f'atr_{period_name}_pct'] = atr_pct.iloc[-1] if not atr_pct.empty else 0

        # è®¡ç®—ä»·æ ¼å˜åŒ– (IOæŒ‡æ ‡) - ä½¿ç”¨åŠ¨æ€å‘¨æœŸ
        io_periods = periods

        io_metrics = {}
        for period_name, period_candles in io_periods.items():
            if len(df) >= period_candles + 1:
                io_change = VolatilityAnalyzer.calculate_price_change(close, period_candles)
                io_metrics[f'io_{period_name}'] = io_change.iloc[-1] if not io_change.empty else 0

        # å½“å‰ä»·æ ¼å’ŒåŸºç¡€ä¿¡æ¯ - ä½¿ç”¨åŠ¨æ€å‘¨æœŸ
        current_price = close.iloc[-1]
        volume_24h_periods = periods['24h']
        volume_24h = df['volume'].tail(volume_24h_periods).sum() if len(df) >= volume_24h_periods else df['volume'].sum()

        # è®¡ç®—æ¢æ‰‹ç‡æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰æŒä»“é‡æ•°æ®ï¼‰
        turnover_metrics = self.calculate_turnover_metrics(df, timeframe_minutes)

        # æ³¢åŠ¨æ€§ç­‰çº§è¯„ä¼°ï¼ˆåŒ…å«æ¢æ‰‹ç‡ï¼‰
        volatility_score = VolatilityAnalyzer.calculate_volatility_score(
            atr_metrics, io_metrics, turnover_metrics
        )

        result = {
            'current_price': current_price,
            'volume_24h': volume_24h,
            'volatility_score': volatility_score,
            'timeframe_minutes': timeframe_minutes,  # æ·»åŠ æ£€æµ‹åˆ°çš„æ—¶é—´å‘¨æœŸä¿¡æ¯
            **atr_metrics,
            **io_metrics,
            'calculated_at': datetime.now().isoformat(),
            'data_points': len(df)
        }

        # å¦‚æœæœ‰æ¢æ‰‹ç‡æ•°æ®ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if turnover_metrics:
            result.update(turnover_metrics)

        return result

    @staticmethod
    def calculate_turnover_rate_raw(volume: pd.Series, open_interest: pd.Series) -> pd.Series:
        """è®¡ç®—åŸå§‹æ¢æ‰‹ç‡ Volume / OI"""
        # é¿å…é™¤é›¶é”™è¯¯
        oi_safe = open_interest.replace(0, np.nan)
        turnover_raw = volume / oi_safe
        return turnover_raw.fillna(0)

    @staticmethod
    def calculate_turnover_rate_normalized(volume: pd.Series, open_interest: pd.Series) -> pd.Series:
        """
        è®¡ç®—å½’ä¸€åŒ–æ¢æ‰‹ç‡ï¼Œæ˜ å°„åˆ° [-0.5, 0.5] åŒºé—´

        æ­¥éª¤ï¼š
        1. R_raw = Volume / OI
        2. R = log(1 + R_raw)  # å¯¹æ•°å‹ç¼©
        3. R_norm = R / (1 + R)  # å½’ä¸€åŒ–åˆ° [0, 1]
        4. TurnoverRate = R_norm - 0.5  # æ˜ å°„åˆ° [-0.5, 0.5]
        """
        # è®¡ç®—åŸå§‹æ¢æ‰‹ç‡
        r_raw = VolatilityAnalyzer.calculate_turnover_rate_raw(volume, open_interest)

        # å¯¹æ•°å‹ç¼©ï¼ˆé¿å…æç«¯å€¼ï¼‰
        r_log = np.log(1 + np.abs(r_raw))

        # å½’ä¸€åŒ–åˆ° [0, 1]
        r_norm = r_log / (1 + r_log)

        # æ˜ å°„åˆ° [-0.5, 0.5]ï¼Œä¿æŒåŸå§‹ç¬¦å·
        turnover_normalized = np.where(r_raw >= 0, r_norm - 0.5, -(r_norm - 0.5))

        return pd.Series(turnover_normalized, index=volume.index)

    def calculate_turnover_metrics(self, df: pd.DataFrame, timeframe_minutes: int = None) -> Dict:
        """è®¡ç®—æ¢æ‰‹ç‡ç›¸å…³æŒ‡æ ‡"""
        if 'open_interest' not in df.columns or len(df) < 2:
            return {}

        volume = df['volume']
        open_interest = df['open_interest']

        # å¦‚æœæ²¡æœ‰æä¾›æ—¶é—´å‘¨æœŸï¼Œè‡ªåŠ¨æ£€æµ‹
        if timeframe_minutes is None:
            timeframe_minutes = self._detect_data_timeframe(df)

        # æ ¹æ®æ•°æ®æ—¶é—´å‘¨æœŸè®¡ç®—å„åˆ†æå‘¨æœŸ
        periods = self._calculate_periods_for_timeframe(timeframe_minutes)

        turnover_metrics = {}

        for period_name, period_candles in periods.items():
            if len(df) >= period_candles:
                # è®¡ç®—è¯¥å‘¨æœŸå†…çš„ç´¯è®¡æˆäº¤é‡å’Œå¹³å‡æŒä»“é‡
                period_volume = volume.rolling(window=period_candles).sum()
                period_oi_avg = open_interest.rolling(window=period_candles).mean()

                # åŸå§‹æ¢æ‰‹ç‡
                raw_turnover = VolatilityAnalyzer.calculate_turnover_rate_raw(
                    period_volume, period_oi_avg
                )

                # å½’ä¸€åŒ–æ¢æ‰‹ç‡
                normalized_turnover = VolatilityAnalyzer.calculate_turnover_rate_normalized(
                    period_volume, period_oi_avg
                )

                # å–æœ€æ–°å€¼
                turnover_metrics[f'turnover_{period_name}_raw'] = raw_turnover.iloc[-1] if not raw_turnover.empty else 0
                turnover_metrics[f'turnover_{period_name}_norm'] = normalized_turnover.iloc[-1] if not normalized_turnover.empty else 0

        # å½“å‰æŒä»“é‡
        current_oi = open_interest.iloc[-1] if not open_interest.empty else 0
        turnover_metrics['current_open_interest'] = current_oi

        return turnover_metrics

    @staticmethod
    def calculate_turnover_level(turnover_raw: float) -> Dict:
        """æ ¹æ®åŸå§‹æ¢æ‰‹ç‡è®¡ç®—æ¢æ‰‹æ°´å¹³"""
        if turnover_raw >= 5.0:
            level = 'EXTREME'  # æé«˜æ¢æ‰‹
            score = 100
        elif turnover_raw >= 3.0:
            level = 'HIGH'     # é«˜æ¢æ‰‹
            score = 80
        elif turnover_raw >= 1.5:
            level = 'MEDIUM'   # ä¸­ç­‰æ¢æ‰‹
            score = 60
        elif turnover_raw >= 0.8:
            level = 'LOW'      # ä½æ¢æ‰‹
            score = 40
        else:
            level = 'MINIMAL'  # æä½æ¢æ‰‹
            score = 20

        return {
            'level': level,
            'score': score
        }

    @staticmethod
    def calculate_volatility_score(atr_metrics: Dict, io_metrics: Dict, turnover_metrics: Dict = None) -> Dict:
        """è®¡ç®—æ³¢åŠ¨æ€§è¯„åˆ†"""
        # ATRè¯„åˆ† (åŸºäºATRç™¾åˆ†æ¯”)
        atr_24h_pct = atr_metrics.get('atr_24h_pct', 0)

        if atr_24h_pct >= 8:
            atr_level = 'EXTREME'  # æé«˜æ³¢åŠ¨
            atr_score = 100
        elif atr_24h_pct >= 5:
            atr_level = 'HIGH'     # é«˜æ³¢åŠ¨
            atr_score = 80
        elif atr_24h_pct >= 3:
            atr_level = 'MEDIUM'   # ä¸­ç­‰æ³¢åŠ¨
            atr_score = 60
        elif atr_24h_pct >= 1.5:
            atr_level = 'LOW'      # ä½æ³¢åŠ¨
            atr_score = 40
        else:
            atr_level = 'MINIMAL'  # æä½æ³¢åŠ¨
            atr_score = 20

        # IOè¯„åˆ† (åŸºäº24å°æ—¶æ¶¨è·Œå¹…)
        io_24h = abs(io_metrics.get('io_24h', 0))

        if io_24h >= 15:
            io_level = 'EXTREME'
            io_score = 100
        elif io_24h >= 10:
            io_level = 'HIGH'
            io_score = 80
        elif io_24h >= 5:
            io_level = 'MEDIUM'
            io_score = 60
        elif io_24h >= 2:
            io_level = 'LOW'
            io_score = 40
        else:
            io_level = 'MINIMAL'
            io_score = 20

        # æ¢æ‰‹ç‡è¯„åˆ†
        turnover_level = 'N/A'
        turnover_score = 0

        if turnover_metrics:
            turnover_24h_raw = turnover_metrics.get('turnover_24h_raw', 0)
            turnover_info = VolatilityAnalyzer.calculate_turnover_level(turnover_24h_raw)
            turnover_level = turnover_info['level']
            turnover_score = turnover_info['score']

        # ç»¼åˆè¯„åˆ† (å¦‚æœæœ‰æ¢æ‰‹ç‡æ•°æ®ï¼Œåˆ™ä¸‰è€…å¹³å‡ï¼›å¦åˆ™ä»ç„¶ä½¿ç”¨ATRå’ŒIO)
        if turnover_metrics:
            overall_score = (atr_score + io_score + turnover_score) / 3
        else:
            overall_score = (atr_score + io_score) / 2

        if overall_score >= 90:
            overall_level = 'EXTREME'
        elif overall_score >= 70:
            overall_level = 'HIGH'
        elif overall_score >= 50:
            overall_level = 'MEDIUM'
        elif overall_score >= 30:
            overall_level = 'LOW'
        else:
            overall_level = 'MINIMAL'

        result = {
            'atr_level': atr_level,
            'atr_score': atr_score,
            'io_level': io_level,
            'io_score': io_score,
            'overall_level': overall_level,
            'overall_score': overall_score
        }

        # å¦‚æœæœ‰æ¢æ‰‹ç‡æ•°æ®ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
        if turnover_metrics:
            result.update({
                'turnover_level': turnover_level,
                'turnover_score': turnover_score
            })

        return result

class VolatilityMonitor(VolatilityAnalyzer):
    """æ³¢åŠ¨æ€§ç›‘æ§å™¨ä¸»ç±»"""

    def __init__(self):
        super().__init__()
        self.data_processor = None

        # ç›‘æ§å‚æ•°
        self.update_interval = 300  # 5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡æ³¢åŠ¨æ€§æŒ‡æ ‡
        self.concurrent_requests = 10
        self.semaphore = Semaphore(self.concurrent_requests)
        self.is_running = False
        self.display_top_count = 15  # é»˜è®¤æ˜¾ç¤ºæ•°é‡

        # ä»é…ç½®æ–‡ä»¶å¯¼å…¥äº¤æ˜“å¯¹åˆ—è¡¨
        try:
            from core.config import DEFAULT_SYMBOLS
            self.symbols = DEFAULT_SYMBOLS
            logger.info(f"å·²ä»é…ç½®æ–‡ä»¶åŠ è½½ {len(self.symbols)} ä¸ªäº¤æ˜“å¯¹")
        except ImportError:
            self.symbols = [
                "BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "ADA/USDT",
                "SOL/USDT", "DOGE/USDT", "DOT/USDT", "UNI/USDT", "LINK/USDT",
                "AVAX/USDT", "MEME/USDT", "PUMP/USDT", "PEOPLE/USDT", "BOME/USDT",
                "ARB/USDT", "MATIC/USDT", "FTM/USDT", "SAND/USDT", "AXS/USDT",
                "NEAR/USDT", "ALGO/USDT", "XLM/USDT", "LIT/USDT", "MKR/USDT"
            ]
            logger.warning("é…ç½®æ–‡ä»¶å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤äº¤æ˜“å¯¹åˆ—è¡¨")

    async def __aenter__(self):
        self.data_processor = CryptoDataProcessor()
        await self.data_processor.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.data_processor:
            await self.data_processor.cleanup()

    def _get_kline_redis_key(self, symbol: str, timeframe: str = '15m') -> str:
        """è·å–Kçº¿æ•°æ®Redisé”®åï¼ˆä¸real_time_data_updateræ ¼å¼ä¸€è‡´ï¼‰"""
        return f"tet:kline:{timeframe}:{symbol.replace('/', '_')}"

    def _get_volatility_redis_key(self, symbol: str) -> str:
        """è·å–æ³¢åŠ¨æ€§æ•°æ®Redisé”®å"""
        return f"tet:volatility:{symbol.replace('/', '_')}"

    def _get_volatility_ranking_key(self) -> str:
        """è·å–æ³¢åŠ¨æ€§æ’è¡Œæ¦œé”®å"""
        return "tet:volatility:ranking"


    def _detect_data_timeframe(self, df: pd.DataFrame) -> int:
        """
        è‡ªåŠ¨æ£€æµ‹æ•°æ®çš„æ—¶é—´å‘¨æœŸï¼ˆè¿”å›åˆ†é’Ÿæ•°ï¼‰

        é€šè¿‡åˆ†ææ—¶é—´ç´¢å¼•çš„é—´éš”æ¥åˆ¤æ–­æ•°æ®å‘¨æœŸ
        """
        if len(df) < 2:
            return 60  # é»˜è®¤1å°æ—¶

        # è®¡ç®—å‰å‡ ä¸ªæ—¶é—´é—´éš”çš„ä¸­ä½æ•°
        time_diffs = []
        for i in range(1, min(10, len(df))):  # æ£€æŸ¥å‰10ä¸ªé—´éš”
            diff = (df.index[i] - df.index[i-1]).total_seconds() / 60
            time_diffs.append(diff)

        if not time_diffs:
            return 60

        median_diff = sorted(time_diffs)[len(time_diffs) // 2]

        # åˆ¤æ–­æœ€æ¥è¿‘çš„æ ‡å‡†æ—¶é—´å‘¨æœŸ
        if median_diff <= 20:
            return 15  # 15åˆ†é’Ÿ
        elif median_diff <= 40:
            return 30  # 30åˆ†é’Ÿ
        elif median_diff <= 90:
            return 60  # 1å°æ—¶
        elif median_diff <= 180:
            return 120  # 2å°æ—¶
        elif median_diff <= 360:
            return 240  # 4å°æ—¶
        else:
            return 1440  # 1å¤©

    def _calculate_periods_for_timeframe(self, timeframe_minutes: int) -> Dict:
        """
        æ ¹æ®æ•°æ®æ—¶é—´å‘¨æœŸè®¡ç®—å„ç§åˆ†æå‘¨æœŸ

        Args:
            timeframe_minutes: æ•°æ®æ—¶é—´å‘¨æœŸï¼ˆåˆ†é’Ÿï¼‰

        Returns:
            åŒ…å«å„ç§åˆ†æå‘¨æœŸçš„å­—å…¸
        """
        # è®¡ç®—å„æ—¶é—´å‘¨æœŸéœ€è¦çš„Kçº¿æ•°é‡
        periods = {
            '1h': max(1, 60 // timeframe_minutes),
            '4h': max(1, 240 // timeframe_minutes),
            '24h': max(1, 1440 // timeframe_minutes)
        }

        return periods

    async def load_market_data(self, symbol: str, fallback_timeframe: str = '1h', fallback_days: int = 30) -> Optional[pd.DataFrame]:
        """ä¼˜å…ˆä»RedisåŠ è½½å¸‚åœºæ•°æ®ï¼Œå¤±è´¥æ—¶ä½¿ç”¨APIä½œä¸ºfallback"""
        try:
            # é¦–å…ˆå°è¯•ä»Redisè·å–æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨15mæ•°æ®ï¼‰
            redis_key = self._get_kline_redis_key(symbol, '15m')
            cached_data = await self.data_processor.redis_client.get(redis_key)

            if cached_data:
                data_info = json.loads(cached_data)

                # æ£€æŸ¥æ•°æ®æ˜¯å¦è¿‡æœŸï¼ˆè¶…è¿‡10åˆ†é’Ÿï¼‰
                last_update = datetime.fromisoformat(data_info['last_update'])
                if datetime.now() - last_update <= timedelta(minutes=10):
                    # è§£æOHLCVæ•°æ®
                    df = pd.read_json(StringIO(data_info['ohlcv_data']), orient='index')
                    df.index = pd.to_datetime(df.index)
                    df.sort_index(inplace=True)

                    if len(df) >= 10:
                        logger.debug(f"{symbol}: ä»Redisè·å–{len(df)}æ¡Kçº¿æ•°æ®")
                        return df
                    else:
                        logger.warning(f"{symbol}: Redisæ•°æ®ä¸è¶³({len(df)}æ¡)")
                else:
                    age_minutes = (datetime.now() - last_update).total_seconds() / 60
                    logger.warning(f"{symbol}: Redisæ•°æ®è¿‡æœŸ({age_minutes:.1f}åˆ†é’Ÿ)")

            # Redisæ•°æ®ä¸å¯ç”¨ï¼Œä½¿ç”¨APIä½œä¸ºfallback
            logger.info(f"{symbol}: Redisæ•°æ®ä¸å¯ç”¨ï¼Œä½¿ç”¨APIè·å–æ•°æ®")
            return await self._fetch_from_api_fallback(symbol, fallback_timeframe, fallback_days)

        except Exception as e:
            logger.error(f"{symbol}: åŠ è½½å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            # å°è¯•API fallback
            try:
                return await self._fetch_from_api_fallback(symbol, fallback_timeframe, fallback_days)
            except Exception as fallback_error:
                logger.error(f"{symbol}: API fallbackä¹Ÿå¤±è´¥: {fallback_error}")
                return None

    async def _fetch_from_api_fallback(self, symbol: str, timeframe: str, lookback_days: int) -> Optional[pd.DataFrame]:
        """API fallbackæ–¹æ³•"""
        try:
            # ç›´æ¥è·å–å†å²æ•°æ®
            data = await self.data_processor.fetch_historical_data(
                symbol, lookback_days, timeframe
            )

            if data.empty or len(data) < 10:
                logger.warning(f"{symbol}: APIæ•°æ®ä¸è¶³ï¼Œè·å–åˆ°{len(data)}æ¡è®°å½•")
                return None

            # å¤„ç†å¸‚åœºæ•°æ®
            processed_data = self.data_processor.process_market_data(data)

            logger.debug(f"{symbol}: APIè·å–{len(processed_data)}æ¡{timeframe}æ•°æ®")
            return processed_data

        except Exception as e:
            logger.error(f"{symbol}: APIè·å–æ•°æ®å¤±è´¥: {e}")
            return None

    async def fetch_open_interest_data(self, symbol: str, df: pd.DataFrame) -> Optional[pd.Series]:
        """
        åŸºäºæˆäº¤é‡ä¼°ç®—æŒä»“é‡æ•°æ®

        Args:
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            df: å¸‚åœºæ•°æ®DataFrame
        """
        try:
            if df is None or len(df) < 10:
                return None

            # è‡ªåŠ¨æ£€æµ‹æ•°æ®å‘¨æœŸå¹¶è®¡ç®—24å°æ—¶å¹³å‡æˆäº¤é‡
            timeframe_minutes = self._detect_data_timeframe(df)
            periods_24h = max(1, 1440 // timeframe_minutes)  # 24å°æ—¶éœ€è¦çš„Kçº¿æ•°é‡

            volume = df['volume']
            avg_volume = volume.rolling(window=min(periods_24h, len(df))).mean()

            # ä¼°ç®—æŒä»“é‡ï¼ˆé€šå¸¸æ˜¯æˆäº¤é‡çš„2-5å€ï¼‰
            # å¯¹äºä¸åŒç±»å‹çš„å¸ç§ä½¿ç”¨ä¸åŒçš„å€æ•°
            if symbol in ['BTC/USDT', 'ETH/USDT']:
                multiplier = 3.0  # ä¸»æµå¸
            elif 'USDT' in symbol:
                multiplier = 2.5  # å…¶ä»–å¸ç§
            else:
                multiplier = 2.0  # å°å¸ç§

            # æ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨ï¼ˆÂ±20%ï¼‰
            np.random.seed(hash(symbol) % 2**32)
            fluctuations = np.random.normal(1.0, 0.1, len(df))

            estimated_oi = avg_volume * multiplier * fluctuations

            # ç¡®ä¿æŒä»“é‡ä¸ºæ­£æ•°
            estimated_oi = np.maximum(estimated_oi, avg_volume * 0.5)

            oi_series = pd.Series(estimated_oi, index=df.index)

            logger.debug(f"{symbol}: ä¼°ç®—æŒä»“é‡ - æ•°æ®å‘¨æœŸ: {timeframe_minutes}åˆ†é’Ÿ, 24héœ€è¦: {periods_24h}ä¸ªKçº¿, å€æ•°: {multiplier}x")
            return oi_series

        except Exception as e:
            logger.debug(f"{symbol}: ä¼°ç®—æŒä»“é‡å¤±è´¥: {e}")
            return None


    async def calculate_volatility_for_symbol(self, symbol: str, fallback_timeframe: str = '1h', fallback_days: int = 30) -> Optional[Dict]:
        """ä¸ºå•ä¸ªäº¤æ˜“å¯¹è®¡ç®—æ³¢åŠ¨æ€§æŒ‡æ ‡"""
        try:
            # ä¼˜å…ˆä»Redisè·å–æ•°æ®ï¼Œå¤±è´¥æ—¶ä½¿ç”¨API fallback
            df = await self.load_market_data(symbol, fallback_timeframe, fallback_days)
            if df is None or len(df) < 10:
                logger.warning(f"{symbol}: æ•°æ®ä¸è¶³æˆ–æ— æ³•åŠ è½½")
                return None

            # å°è¯•è·å–æŒä»“é‡æ•°æ®
            try:
                oi_series = await self.fetch_open_interest_data(symbol, df)
                if oi_series is not None and len(oi_series) == len(df):
                    df['open_interest'] = oi_series
                    logger.debug(f"{symbol}: æˆåŠŸæ·»åŠ ä¼°ç®—æŒä»“é‡æ•°æ®")
            except Exception as oi_error:
                logger.debug(f"{symbol}: è·å–æŒä»“é‡æ•°æ®å¤±è´¥: {oi_error}")

            # è®¡ç®—æ³¢åŠ¨æ€§æŒ‡æ ‡ï¼ˆåŒ…å«æ¢æ‰‹ç‡å¦‚æœæœ‰æŒä»“é‡æ•°æ®ï¼‰
            volatility_metrics = self.calculate_volatility_metrics(df)
            if volatility_metrics is None:
                logger.warning(f"{symbol}: æ³¢åŠ¨æ€§è®¡ç®—å¤±è´¥")
                return None

            # æ·»åŠ ç¬¦å·æ ‡è¯†
            volatility_metrics['symbol'] = symbol

            return volatility_metrics

        except Exception as e:
            logger.error(f"{symbol}: æ³¢åŠ¨æ€§è®¡ç®—å¼‚å¸¸: {e}")
            return None

    def _convert_numpy_types(self, obj):
        """é€’å½’è½¬æ¢numpy/pandasç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
        if isinstance(obj, dict):
            return {key: self._convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        elif isinstance(obj, (np.integer, np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64, np.float32)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        else:
            return obj

    async def store_volatility_results(self, volatility_data: Dict):
        """å°†æ³¢åŠ¨æ€§ç»“æœå­˜å‚¨åˆ°Redis"""
        redis_client = None
        try:
            # åˆ›å»ºä¸´æ—¶Redisè¿æ¥
            from data_processor import CryptoDataProcessor
            temp_processor = CryptoDataProcessor()
            await temp_processor.initialize()
            redis_client = temp_processor.redis_client

            # å­˜å‚¨æ¯ä¸ªç¬¦å·çš„æ³¢åŠ¨æ€§æ•°æ®
            for symbol, data in volatility_data.items():
                if data is not None:
                    redis_key = self._get_volatility_redis_key(symbol)

                    # è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
                    converted_data = self._convert_numpy_types(data)

                    # å­˜å‚¨æ•°æ®ï¼ˆ30åˆ†é’Ÿè¿‡æœŸï¼‰
                    await redis_client.setex(
                        redis_key, 1800, json.dumps(converted_data)
                    )

            # æ›´æ–°æ’è¡Œæ¦œ
            await self._update_volatility_ranking(volatility_data, redis_client)

            logger.info(f"å·²å°†{len([d for d in volatility_data.values() if d is not None])}ä¸ªç¬¦å·çš„æ³¢åŠ¨æ€§æ•°æ®ä¿å­˜åˆ°Redis")

        except Exception as e:
            logger.error(f"å­˜å‚¨æ³¢åŠ¨æ€§æ•°æ®åˆ°Rediså¤±è´¥: {e}")
        finally:
            # æ¸…ç†ä¸´æ—¶è¿æ¥
            if redis_client:
                try:
                    await temp_processor.cleanup()
                except Exception:
                    pass

    async def _update_volatility_ranking(self, volatility_data: Dict, redis_client):
        """æ›´æ–°æ³¢åŠ¨æ€§æ’è¡Œæ¦œ"""
        try:
            ranking_key = self._get_volatility_ranking_key()

            # æ¸…é™¤æ—§çš„æ’è¡Œæ¦œ
            await redis_client.delete(ranking_key)

            # æ·»åŠ æ–°çš„æ’è¡Œæ¦œæ•°æ®
            ranking_scores = {}
            for symbol, data in volatility_data.items():
                if data is not None and 'volatility_score' in data:
                    overall_score = data['volatility_score']['overall_score']
                    ranking_scores[symbol] = overall_score

            if ranking_scores:
                # æ‰¹é‡æ·»åŠ åˆ°sorted set
                await redis_client.zadd(ranking_key, ranking_scores)

                # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ30åˆ†é’Ÿï¼‰
                await redis_client.expire(ranking_key, 1800)

            logger.debug(f"å·²æ›´æ–°æ³¢åŠ¨æ€§æ’è¡Œæ¦œï¼ŒåŒ…å«{len(ranking_scores)}ä¸ªç¬¦å·")

        except Exception as e:
            logger.error(f"æ›´æ–°æ³¢åŠ¨æ€§æ’è¡Œæ¦œå¤±è´¥: {e}")


    async def process_single_symbol(self, symbol: str, fallback_timeframe: str = '1h', fallback_days: int = 30) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªäº¤æ˜“å¯¹çš„æ³¢åŠ¨æ€§åˆ†æ"""
        async with self.semaphore:
            try:
                # è®¡ç®—æ³¢åŠ¨æ€§æŒ‡æ ‡
                volatility_data = await self.calculate_volatility_for_symbol(symbol, fallback_timeframe, fallback_days)
                if volatility_data is None:
                    return None

                # è¾“å‡ºå…³é”®ä¿¡æ¯
                self._log_volatility_summary(symbol, volatility_data)

                return volatility_data

            except Exception as e:
                logger.error(f"{symbol}: å¤„ç†å¤±è´¥: {e}")
                return None

    def _log_volatility_summary(self, symbol: str, data: Dict):
        """è¾“å‡ºæ³¢åŠ¨æ€§æ‘˜è¦ä¿¡æ¯"""
        try:
            score = data['volatility_score']
            base_info = (f"{symbol}: æ³¢åŠ¨æ€§ {score['overall_level']}({score['overall_score']:.0f}åˆ†) | "
                        f"ATR24h: {data.get('atr_24h_pct', 0):.2f}% | "
                        f"IO24h: {data.get('io_24h', 0):+.2f}%")

            # å¦‚æœæœ‰æ¢æ‰‹ç‡æ•°æ®ï¼Œæ·»åŠ åˆ°è¾“å‡ºä¸­
            if 'turnover_24h_raw' in data:
                turnover_info = f" | TO24h: {data.get('turnover_24h_raw', 0):.2f}x"
                base_info += turnover_info

            base_info += f" | ä»·æ ¼: ${data['current_price']:.6f}"
            logger.info(base_info)

        except Exception as e:
            logger.debug(f"{symbol}: æ—¥å¿—è¾“å‡ºå¤±è´¥: {e}")

    async def scan_all_symbols(self, fallback_timeframe: str = '1h', fallback_days: int = 30) -> Dict:
        """æ‰«ææ‰€æœ‰äº¤æ˜“å¯¹çš„æ³¢åŠ¨æ€§"""
        start_time = time.time()
        logger.info(f"å¼€å§‹æ³¢åŠ¨æ€§æ‰«æï¼Œå…±{len(self.symbols)}ä¸ªäº¤æ˜“å¯¹...")

        # å¹¶å‘å¤„ç†æ‰€æœ‰äº¤æ˜“å¯¹
        tasks = [self.process_single_symbol(symbol, fallback_timeframe, fallback_days) for symbol in self.symbols]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # æ•´ç†ç»“æœ
        volatility_results = {}
        successful_count = 0

        for i, result in enumerate(results):
            symbol = self.symbols[i]

            if isinstance(result, Exception):
                logger.error(f"Error processing {symbol}: {result}")
                volatility_results[symbol] = None
            elif result is not None:
                volatility_results[symbol] = result
                successful_count += 1
            else:
                volatility_results[symbol] = None

        failed_count = len(results) - successful_count
        elapsed_time = time.time() - start_time

        scan_summary = {
            "scan_time": elapsed_time,
            "total_symbols": len(self.symbols),
            "successful_count": successful_count,
            "failed_count": failed_count,
            "timestamp": datetime.now().isoformat(),
            "volatility_data": volatility_results
        }

        logger.info(f"æ³¢åŠ¨æ€§æ‰«æå®Œæˆ: {successful_count}/{len(self.symbols)} æˆåŠŸ, "
                   f"è€—æ—¶ {elapsed_time:.1f}ç§’")

        # å­˜å‚¨ç»“æœåˆ°Redis
        try:
            await self.store_volatility_results(volatility_results)
        except Exception as e:
            logger.warning(f"å­˜å‚¨åˆ°Rediså¤±è´¥: {e}")

        return scan_summary

    def get_volatility_ranking(self, volatility_data: Dict, limit: int = 10) -> List[Dict]:
        """ä»æ‰«æç»“æœç”Ÿæˆæ³¢åŠ¨æ€§æ’è¡Œæ¦œ"""
        try:
            ranking_list = []

            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®å¹¶æŒ‰æ³¢åŠ¨æ€§è¯„åˆ†æ’åº
            valid_data = [(symbol, data) for symbol, data in volatility_data.items()
                         if data is not None and 'volatility_score' in data]

            valid_data.sort(key=lambda x: x[1]['volatility_score']['overall_score'], reverse=True)

            # ç”Ÿæˆæ’è¡Œæ¦œ
            for i, (symbol, data) in enumerate(valid_data[:limit], 1):
                ranking_item = {
                    'rank': i,
                    'symbol': symbol,
                    'score': data['volatility_score']['overall_score'],
                    'level': data['volatility_score']['overall_level'],
                    'atr_24h_pct': data.get('atr_24h_pct', 0),
                    'io_24h': data.get('io_24h', 0),
                    'current_price': data.get('current_price', 0),
                    'timeframe_minutes': data.get('timeframe_minutes', 0)
                }

                # å¦‚æœæœ‰æ¢æ‰‹ç‡æ•°æ®ï¼Œæ·»åŠ åˆ°æ’è¡Œæ¦œé¡¹ç›®ä¸­
                if 'turnover_24h_raw' in data:
                    ranking_item['turnover_24h_raw'] = data.get('turnover_24h_raw', 0)

                ranking_list.append(ranking_item)

            return ranking_list

        except Exception as e:
            logger.error(f"ç”Ÿæˆæ³¢åŠ¨æ€§æ’è¡Œæ¦œå¤±è´¥: {e}")
            return []

    async def get_volatility_ranking_from_redis(self, limit: int = 10) -> List[Dict]:
        """ä»Redisè·å–æ³¢åŠ¨æ€§æ’è¡Œæ¦œï¼ˆå¤‡é€‰æ–¹æ³•ï¼‰"""
        redis_client = None
        try:
            # åˆ›å»ºä¸´æ—¶Redisè¿æ¥
            from data_processor import CryptoDataProcessor
            temp_processor = CryptoDataProcessor()
            await temp_processor.initialize()
            redis_client = temp_processor.redis_client

            ranking_key = self._get_volatility_ranking_key()

            # è·å–å‰Nä¸ªæœ€é«˜æ³¢åŠ¨æ€§çš„äº¤æ˜“å¯¹ï¼ˆé™åºï¼‰
            top_symbols = await redis_client.zrevrange(
                ranking_key, 0, limit - 1, withscores=True
            )

            ranking_list = []
            for i, (symbol_bytes, score) in enumerate(top_symbols, 1):
                symbol = symbol_bytes.decode('utf-8') if isinstance(symbol_bytes, bytes) else symbol_bytes

                # è·å–è¯¦ç»†çš„æ³¢åŠ¨æ€§æ•°æ®
                volatility_key = self._get_volatility_redis_key(symbol)
                volatility_data = await redis_client.get(volatility_key)

                if volatility_data:
                    data = json.loads(volatility_data)
                    ranking_item = {
                        'rank': i,
                        'symbol': symbol,
                        'score': score,
                        'level': data['volatility_score']['overall_level'],
                        'atr_24h_pct': data.get('atr_24h_pct', 0),
                        'io_24h': data.get('io_24h', 0),
                        'current_price': data.get('current_price', 0),
                        'timeframe_minutes': data.get('timeframe_minutes', 0)
                    }

                    # å¦‚æœæœ‰æ¢æ‰‹ç‡æ•°æ®ï¼Œæ·»åŠ åˆ°æ’è¡Œæ¦œé¡¹ç›®ä¸­
                    if 'turnover_24h_raw' in data:
                        ranking_item['turnover_24h_raw'] = data.get('turnover_24h_raw', 0)

                    ranking_list.append(ranking_item)

            return ranking_list

        except Exception as e:
            logger.error(f"ä»Redisè·å–æ³¢åŠ¨æ€§æ’è¡Œæ¦œå¤±è´¥: {e}")
            return []
        finally:
            # æ¸…ç†ä¸´æ—¶è¿æ¥
            if redis_client:
                try:
                    await temp_processor.cleanup()
                except Exception:
                    pass

    def display_volatility_report(self, scan_results: Dict, top_count: int = 15):
        """æ˜¾ç¤ºæ³¢åŠ¨æ€§æŠ¥å‘Š"""
        try:
            # ä»æ‰«æç»“æœç”Ÿæˆæ’è¡Œæ¦œ
            volatility_data = scan_results.get('volatility_data', {})
            top_volatile = self.get_volatility_ranking(volatility_data, top_count)

            if top_volatile:
                # æ˜¾ç¤ºç®€åŒ–çš„æ³¢åŠ¨æ€§æŠ¥å‘Šï¼ˆå»æ‰æ¢æ‰‹ç­‰çº§å’Œå½’ä¸€åŒ–TOï¼‰
                logger.info("=" * 80)
                logger.info(f"ğŸ“Š æ³¢åŠ¨æ€§ä¸æ¢æ‰‹ç‡æ’è¡Œæ¦œ (TOP {top_count})")
                logger.info("=" * 80)
                logger.info(f"{'æ’å':<6} {'äº¤æ˜“å¯¹':<8} {'æ³¢åŠ¨ç­‰çº§':<8} {'ATR24h%':<9} "
                           f"{'IO24h%':<9} {'æ¢æ‰‹24h':<10} {'å½“å‰ä»·æ ¼':<14}")
                logger.info("-" * 80)

                for item in top_volatile:
                    turnover_raw = item.get('turnover_24h_raw', 0)

                    # å¦‚æœæ²¡æœ‰æ¢æ‰‹ç‡æ•°æ®ï¼Œæ˜¾ç¤ºå ä½ç¬¦
                    if turnover_raw == 0 and 'turnover_24h_raw' not in item:
                        turnover_display = "N/A"
                    else:
                        turnover_display = f"{turnover_raw:.2f}x"

                    logger.info(f"{item['rank']:<6} {item['symbol']:<12} {item['level']:<12} "
                               f"{item['atr_24h_pct']:<9.2f} "
                               f"{item['io_24h']:<9.2f} {turnover_display:<10} "
                               f"${item['current_price']:<13.6f}")

                logger.info("-" * 80)

                # æ·»åŠ æ¢æ‰‹ç‡ç»Ÿè®¡æ‘˜è¦
                valid_turnovers = [item.get('turnover_24h_raw', 0) for item in top_volatile if item.get('turnover_24h_raw', 0) > 0]
                if valid_turnovers:
                    avg_turnover = sum(valid_turnovers) / len(valid_turnovers)
                    max_turnover = max(valid_turnovers)
                    min_turnover = min(valid_turnovers)

                    logger.info(f"ğŸ“ˆ æ¢æ‰‹ç‡ç»Ÿè®¡: å¹³å‡ {avg_turnover:.2f}x | æœ€é«˜ {max_turnover:.2f}x | æœ€ä½ {min_turnover:.2f}x | æœ‰æ•ˆæ•°æ® {len(valid_turnovers)}/{len(top_volatile)}")
                else:
                    logger.info(f"ğŸ“ˆ æ¢æ‰‹ç‡ç»Ÿè®¡: æš‚æ— æœ‰æ•ˆæ•°æ® (å¯èƒ½éœ€è¦æŒä»“é‡æ•°æ®)")

                logger.info("=" * 80)
            else:
                logger.warning("æš‚æ— æ³¢åŠ¨æ€§æ•°æ®")

        except Exception as e:
            logger.error(f"æ˜¾ç¤ºæ³¢åŠ¨æ€§æŠ¥å‘Šå¤±è´¥: {e}")

    async def run_continuous(self, fallback_timeframe: str = '1h', fallback_days: int = 30):
        """æŒç»­è¿è¡Œæ³¢åŠ¨æ€§ç›‘æ§"""
        self.is_running = True
        logger.info(f"æ³¢åŠ¨æ€§ç›‘æ§æœåŠ¡å¯åŠ¨ï¼Œæ›´æ–°é—´éš”: {self.update_interval}ç§’")
        logger.info(f"ä¼˜å…ˆä½¿ç”¨Redisç¼“å­˜æ•°æ®ï¼Œfallbackå‚æ•°: {fallback_timeframe} æ—¶é—´æ¡†æ¶, {fallback_days}å¤©å†å²æ•°æ®")

        while self.is_running:
            try:
                # æ‰§è¡Œæ‰«æ
                scan_result = await self.scan_all_symbols(fallback_timeframe, fallback_days)

                # æ˜¾ç¤ºæŠ¥å‘Š
                self.display_volatility_report(scan_result, self.display_top_count)

                # ç­‰å¾…ä¸‹æ¬¡æ‰«æ
                if self.is_running:
                    await asyncio.sleep(self.update_interval)

            except KeyboardInterrupt:
                logger.info("æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­...")
                self.is_running = False
                break
            except Exception as e:
                logger.error(f"ç›‘æ§å¾ªç¯å‡ºé”™: {e}")
                await asyncio.sleep(60)

        logger.info("æ³¢åŠ¨æ€§ç›‘æ§æœåŠ¡å·²åœæ­¢")

    async def run_single_scan(self, fallback_timeframe: str = '1h', fallback_days: int = 30, top_count: int = 15) -> Dict:
        """æ‰§è¡Œå•æ¬¡æ‰«æ"""
        logger.info("æ‰§è¡Œå•æ¬¡æ³¢åŠ¨æ€§æ‰«æ...")
        logger.info(f"ä¼˜å…ˆä½¿ç”¨Redisç¼“å­˜æ•°æ®ï¼Œfallbackå‚æ•°: {fallback_timeframe} æ—¶é—´æ¡†æ¶, {fallback_days}å¤©å†å²æ•°æ®")
        scan_result = await self.scan_all_symbols(fallback_timeframe, fallback_days)
        self.display_volatility_report(scan_result, top_count)
        return scan_result

    def stop(self):
        """åœæ­¢æœåŠ¡"""
        self.is_running = False

async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='TETæ³¢åŠ¨æ€§ä¸æ¢æ‰‹ç‡ç›‘æ§æœåŠ¡')
    parser.add_argument('--once', action='store_true', help='åªæ‰§è¡Œä¸€æ¬¡æ‰«æåé€€å‡º')
    parser.add_argument('--interval', type=int, default=300, help='æ‰«æé—´éš”ï¼ˆç§’ï¼‰')
    parser.add_argument('--top', type=int, default=15, help='æ˜¾ç¤ºæ’è¡Œæ¦œæ•°é‡')
    parser.add_argument('--timeframe', type=str, default='1h', help='æ•°æ®æ—¶é—´æ¡†æ¶ (15m, 30m, 1h, 4h, 1d)')
    parser.add_argument('--days', type=int, default=30, help='å†å²æ•°æ®å¤©æ•°')
    parser.add_argument('--example', action='store_true', help='æ˜¾ç¤ºæ¢æ‰‹ç‡è®¡ç®—ç¤ºä¾‹å¹¶é€€å‡º')

    args = parser.parse_args()

    # å¦‚æœæ˜¯æ˜¾ç¤ºç¤ºä¾‹ï¼Œç›´æ¥è°ƒç”¨ç¤ºä¾‹å‡½æ•°å¹¶é€€å‡º
    if args.example:
        calculate_turnover_rate_example()
        return

    logger.info("å¯åŠ¨TETæ³¢åŠ¨æ€§ä¸æ¢æ‰‹ç‡ç›‘æ§æœåŠ¡...")
    logger.info(f"å‚æ•°: {args.timeframe} æ—¶é—´æ¡†æ¶, {args.days}å¤©å†å²æ•°æ®, æ˜¾ç¤ºTOP{args.top}")

    async with VolatilityMonitor() as monitor:
        if args.interval != 300:
            monitor.update_interval = args.interval

        try:
            if args.once:
                # å•æ¬¡æ‰«ææ¨¡å¼
                result = await monitor.run_single_scan(args.timeframe, args.days, args.top)
                print(f"\næ³¢åŠ¨æ€§æ‰«æå®Œæˆ:")
                print(f"æˆåŠŸ: {result['successful_count']}/{result['total_symbols']}")
                print(f"è€—æ—¶: {result['scan_time']:.1f}ç§’")
            else:
                # æŒç»­ç›‘æ§æ¨¡å¼
                monitor.display_top_count = args.top
                await monitor.run_continuous(args.timeframe, args.days)

        except KeyboardInterrupt:
            logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")

def calculate_turnover_rate_example():
    """
    æ¢æ‰‹ç‡è®¡ç®—ç¤ºä¾‹å‡½æ•°

    å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ¢æ‰‹ç‡è®¡ç®—åŠŸèƒ½ï¼š
    1. åŸå§‹æ¢æ‰‹ç‡ = Volume / Open Interest
    2. å½’ä¸€åŒ–æ¢æ‰‹ç‡æ˜ å°„åˆ° [-0.5, 0.5] åŒºé—´
    """
    print("\n" + "="*60)
    print("ğŸ“Š åˆçº¦æ¢æ‰‹ç‡è®¡ç®—ç¤ºä¾‹")
    print("="*60)

    # ç¤ºä¾‹æ•°æ®
    examples = [
        {"symbol": "BTC/USDT", "volume": 1000000000, "oi": 500000000},  # 2.0xæ¢æ‰‹
        {"symbol": "ETH/USDT", "volume": 800000000, "oi": 400000000},   # 2.0xæ¢æ‰‹
        {"symbol": "MEME/USDT", "volume": 500000000, "oi": 100000000},  # 5.0xæ¢æ‰‹
        {"symbol": "STABLE/USDT", "volume": 100000000, "oi": 200000000}, # 0.5xæ¢æ‰‹
    ]

    print(f"{'äº¤æ˜“å¯¹':<12} {'æˆäº¤é‡(USD)':<15} {'æŒä»“é‡(USD)':<15} {'åŸå§‹æ¢æ‰‹ç‡':<12} {'å½’ä¸€åŒ–æ¢æ‰‹ç‡':<15} {'æ¢æ‰‹ç­‰çº§':<10}")
    print("-" * 95)

    for example in examples:
        symbol = example["symbol"]
        volume = example["volume"]
        oi = example["oi"]

        # è®¡ç®—åŸå§‹æ¢æ‰‹ç‡
        raw_rate = volume / oi if oi > 0 else 0

        # è®¡ç®—å½’ä¸€åŒ–æ¢æ‰‹ç‡ (æ˜ å°„åˆ° [-0.5, 0.5])
        r_log = math.log(1 + abs(raw_rate))
        r_norm = r_log / (1 + r_log)
        normalized_rate = r_norm - 0.5

        # è®¡ç®—æ¢æ‰‹ç­‰çº§
        level_info = VolatilityAnalyzer.calculate_turnover_level(raw_rate)
        level = level_info['level']

        print(f"{symbol:<12} {volume:>13,.0f} {oi:>13,.0f} {raw_rate:>10.2f}x "
              f"{normalized_rate:>13.3f} {level:<10}")

    print("="*60)
    print("è¯´æ˜ï¼š")
    print("â€¢ åŸå§‹æ¢æ‰‹ç‡ = æˆäº¤é‡ Ã· æŒä»“é‡")
    print("â€¢ å½’ä¸€åŒ–æ¢æ‰‹ç‡èŒƒå›´ï¼š[-0.5, 0.5]ï¼Œ0é™„è¿‘ä¸ºæ­£å¸¸ï¼ŒÂ±0.5ä¸ºæå€¼")
    print("â€¢ æ¢æ‰‹ç­‰çº§ï¼šMINIMAL < LOW < MEDIUM < HIGH < EXTREME")
    print("â€¢ é«˜æ¢æ‰‹ç‡é€šå¸¸æ„å‘³ç€å¸‚åœºæ´»è·ƒåº¦é«˜ï¼Œä½†ä¹Ÿå¯èƒ½ä¼´éšé«˜æ³¢åŠ¨")
    print("="*60 + "\n")

if __name__ == "__main__":
    import sys

    # æ£€æŸ¥æ˜¯å¦è¦è¿è¡Œç¤ºä¾‹
    if len(sys.argv) > 1 and sys.argv[1] == '--example':
        calculate_turnover_rate_example()
        sys.exit(0)

    asyncio.run(main())