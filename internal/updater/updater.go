package updater

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"runtime"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	"tet-data-service/internal/binance"
	"tet-data-service/internal/config"
	redisClient "tet-data-service/internal/redis"

	"github.com/sirupsen/logrus"
	"golang.org/x/time/rate"
)

// ç»Ÿä¸€æ—¶é—´æ ¼å¼ï¼ˆCST=UTC+8ï¼‰
const TimeFormat = "2006-01-02T15:04:05.000"

var cst = time.FixedZone("CST", 8*3600)

type DataUpdater struct {
	config        *config.Config
	binanceClient *binance.Client
	redisClient   *redisClient.Client
	rateLimiter   *rate.Limiter
	semaphore     chan struct{}
	isRunning     bool
	mu            sync.RWMutex
	timeframes    []string

    stats struct {
        sync.RWMutex
        successCount int
        failureCount int
        lastUpdate   time.Time
    }
}

const (
	initialKlineCount = 1000 // é»˜è®¤å¤§å®¹é‡ï¼Œä»…ç”¨äºéåˆ†æ¡£å‘¨æœŸ
	maxStoredCandles  = initialKlineCount
)

type ResourceUsage struct {
	APICallsPerHour    float64
	EstimatedMemoryMB  int
	BandwidthPerHourMB float64
}

func New(cfg *config.Config) (*DataUpdater, error) {
	// Binance client
	bc := binance.NewClient(
		cfg.BinanceBaseURL,
		cfg.APIRequestsPerSec,
	)

	// Redis client
	rc := redisClient.NewClient(cfg.RedisAddr, cfg.RedisPassword, cfg.RedisDB)

	// å¹¶å‘ä¿¡å·é‡
	if cfg.ConcurrentRequests <= 0 {
		cfg.ConcurrentRequests = 10
	}
	semaphore := make(chan struct{}, cfg.ConcurrentRequests)
	for i := 0; i < cfg.ConcurrentRequests; i++ {
		semaphore <- struct{}{}
	}

	// é™é€Ÿå™¨å…œåº•
	if cfg.APIRequestsPerSec <= 0 {
		logrus.Warnf("APIRequestsPerSec=%d is invalid; default to 10 rps", cfg.APIRequestsPerSec)
		cfg.APIRequestsPerSec = 10
	}

	updater := &DataUpdater{
		config:        cfg,
		binanceClient: bc,
		redisClient:   rc,
		rateLimiter:   rate.NewLimiter(rate.Limit(cfg.APIRequestsPerSec), cfg.APIRequestsPerSec),
		semaphore:     semaphore,
	}

	// è§£æ/æ ¡éªŒ TIMEFRAMES
	if len(cfg.Timeframes) == 0 {
		return nil, fmt.Errorf("no timeframes configured")
	}
	unique := make(map[string]struct{})
	for _, raw := range cfg.Timeframes {
		tf := strings.TrimSpace(raw)
		if tf == "" {
			continue
		}
		if _, ok := unique[tf]; ok {
			continue
		}
		if binance.ParseInterval(tf) <= 0 {
			logrus.Warnf("â›” TIMEFRAMES contains unsupported interval: %q (skipped)", tf)
			continue
		}
		unique[tf] = struct{}{}
		updater.timeframes = append(updater.timeframes, tf)
	}
	if len(updater.timeframes) == 0 {
		return nil, fmt.Errorf("no valid timeframes configured (after validation)")
	}
	logrus.Infof("ğŸ§© Timeframes enabled: %v", updater.timeframes)

	return updater, nil
}

func (u *DataUpdater) Start(ctx context.Context) error {
	u.mu.Lock()
	u.isRunning = true
	u.mu.Unlock()

	logrus.Info("ğŸš€ TET Real-Time Data Service started")
	logrus.Infof("âš™ï¸  Config | Concurrent: %d", u.config.ConcurrentRequests)
	logrus.Infof("âš™ï¸  Config | Rate limit: %d rps", u.config.APIRequestsPerSec)
	logrus.Infof("âš™ï¸  Config | Max data age: %v", u.config.MaxDataAge)
	logrus.Infof("ğŸ“Š Monitor | %d symbols Ã— %d timeframes", len(u.config.Symbols), len(u.timeframes))

	loopCtx, cancel := context.WithCancel(ctx)
	defer cancel()

	// å¯åŠ¨å€’è®¡æ—¶æ˜¾ç¤ºåç¨‹
	go u.startCountdownDisplay(loopCtx)

	// å¯åŠ¨å…¨å±€ 15 åˆ†é’Ÿå¯¹é½å¼ºåˆ¶â€œå…¨é‡â€åˆ·æ–°è°ƒåº¦ï¼ˆå¯¹æ‰€æœ‰ timeframeï¼‰
	go func() {
		if err := u.runQuarterHourlyLoop(loopCtx); err != nil && !errors.Is(err, context.Canceled) {
			logrus.Errorf("Quarter scheduler error: %v", err)
		}
	}()

	// é¦–è½®å›å¡«ï¼ˆæŒ‰ä½ ç°æœ‰é€»è¾‘ï¼›å¯é€‰ä¿ç•™ï¼‰
	for _, timeframe := range u.timeframes {
		logrus.Infof("ğŸ”„ Initial | [%s] starting initial update...", timeframe)
		success, failed, err := u.updateAllSymbolsForTimeframeWithType(loopCtx, timeframe, "initial")
		if err != nil {
			logrus.Errorf("âŒ Initial | [%s] %v", timeframe, err)
		} else {
			logrus.Infof("âœ… Initial | [%s] ğŸŸ¢%d ğŸ”´%d", timeframe, success, failed)
		}
	}

	errCh := make(chan error, len(u.timeframes))
	var wg sync.WaitGroup

	// åŸæœ‰çš„â€œæŒ‰æ”¶ç›˜æ—¶é—´â€å¾ªç¯ï¼ˆå¯é€‰ä¿ç•™ï¼‰
	for _, timeframe := range u.timeframes {
		tf := timeframe
		wg.Add(1)
		go func() {
			defer wg.Done()
			if err := u.runTimeframeLoop(loopCtx, tf); err != nil && !errors.Is(err, context.Canceled) {
				select {
				case errCh <- fmt.Errorf("timeframe %s: %w", tf, err):
				default:
				}
			}
		}()
	}

	var runErr error
	select {
	case <-ctx.Done():
		runErr = ctx.Err()
	case err := <-errCh:
		runErr = err
	}

	cancel()
	wg.Wait()

	u.mu.Lock()
	u.isRunning = false
	u.mu.Unlock()

	if runErr != nil && !errors.Is(runErr, context.Canceled) {
		return runErr
	}
	return runErr
}

func (u *DataUpdater) runTimeframeLoop(ctx context.Context, timeframe string) error {
	baseInterval := u.resolveInterval(timeframe)
	currentInterval := baseInterval

	// è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªKçº¿æ”¶ç›˜æ—¶é—´çš„å»¶è¿Ÿ
	firstDelay := timeUntilNextKlineClose(currentInterval)
	logrus.Infof("â±ï¸  [%s] first tick in %s (interval=%s, +5s delay)", timeframe, firstDelay.Truncate(time.Millisecond), currentInterval)

	timer := time.NewTimer(firstDelay)
	defer timer.Stop()

	for {
		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-timer.C:
		}

		// ç¡®ä¿ä¸ä¼šè¿‡æ—©æ›´æ–°ï¼Œæ£€æŸ¥æ˜¯å¦è¿‡äº†Kçº¿æ”¶ç›˜æ—¶é—´
		nextBoundary := timeUntilNextBoundary(currentInterval)
		if nextBoundary > 10*time.Second {
			// å¦‚æœè·ç¦»ä¸‹æ¬¡è¾¹ç•Œè¿˜æœ‰è¶…è¿‡10ç§’ï¼Œè¯´æ˜å®šæ—¶å™¨æå‰è§¦å‘äº†ï¼Œç­‰å¾…åˆ°å®‰å…¨æ—¶é—´
			logrus.Warnf("âš ï¸  [%s] timer fired too early, waiting (remaining: %v)", timeframe, nextBoundary)
			timer.Reset(nextBoundary + 5*time.Second)
			continue
		}

		if err := u.runTimeframeCycle(ctx, timeframe); err != nil {
			logrus.Errorf("âŒ Cycle   | [%s] %v", timeframe, err)
		}

		if u.config.AdaptiveInterval {
			newInterval := u.calculateOptimalInterval(currentInterval, baseInterval)
			if newInterval != currentInterval {
				currentInterval = newInterval
			}
		} else {
			currentInterval = baseInterval
		}

		// è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªKçº¿æ”¶ç›˜æ—¶é—´çš„å»¶è¿Ÿ
		nextDelay := timeUntilNextKlineClose(currentInterval)
		logrus.Debugf("â±ï¸  [%s] next tick in %s (+5s delay)", timeframe, nextDelay.Truncate(time.Millisecond))
		timer.Reset(nextDelay)
	}
}

func (u *DataUpdater) runTimeframeCycle(ctx context.Context, timeframe string) error {
	loopStart := time.Now()

	stale, err := u.checkStaleData(ctx, timeframe)
	if err != nil {
		logrus.Errorf("[%s] stale check error: %v", timeframe, err)
	} else if len(stale) > 0 {
		logrus.Warnf("âš ï¸  Stale   | [%s] %d stale symbols, urgent updating...", timeframe, len(stale))
		u.urgentUpdate(ctx, timeframe, stale)
	}

	success, failed, err := u.UpdateAllSymbolsForTimeframe(ctx, timeframe)
	if err != nil {
		return err
	}

	logrus.Infof("ğŸ”„ Cycle   | [%s] âœ…%d âŒ%d â±ï¸ %.1fs", timeframe, success, failed, time.Since(loopStart).Seconds())
	return nil
}

func (u *DataUpdater) UpdateAllSymbolsForTimeframe(ctx context.Context, timeframe string) (int, int, error) {
	return u.updateAllSymbolsForTimeframeWithType(ctx, timeframe, "regular")
}

func (u *DataUpdater) updateAllSymbolsForTimeframeWithType(ctx context.Context, timeframe string, updateType string) (int, int, error) {
	start := time.Now()
	logrus.Infof("ğŸ“Š Batch   | [%s] %d symbols...", timeframe, len(u.config.Symbols))

	results := make(chan bool, len(u.config.Symbols))
	failedSymbols := make([]string, 0)
	var failedMu sync.Mutex

	batchSize := u.config.BatchSize
	if batchSize <= 0 {
		batchSize = u.config.ConcurrentRequests
	}
	if batchSize <= 0 {
		batchSize = len(u.config.Symbols)
	}
	if batchSize > len(u.config.Symbols) {
		batchSize = len(u.config.Symbols)
	}
	if u.config.ConcurrentRequests > 0 && batchSize > u.config.ConcurrentRequests {
		batchSize = u.config.ConcurrentRequests
	}

	totalBatches := 1
	if batchSize > 0 {
		totalBatches = (len(u.config.Symbols) + batchSize - 1) / batchSize
	}

	var wg sync.WaitGroup
	for i := 0; i < len(u.config.Symbols); i += batchSize {
		end := i + batchSize
		if end > len(u.config.Symbols) {
			end = len(u.config.Symbols)
		}
		batch := u.config.Symbols[i:end]
		logrus.Infof("ğŸ“¦ Batch   | [%s] %d/%d (%d symbols) %v", timeframe, i/batchSize+1, totalBatches, len(batch), batch)

		for _, symbol := range batch {
			sym := symbol
			wg.Add(1)
			go func() {
				defer wg.Done()
				// regular/initial ä»æŒ‰åŸé€»è¾‘ï¼ˆå¢é‡ä¼˜å…ˆï¼‰ï¼Œquarter æˆ‘ä»¬èµ°å¼ºåˆ¶â€œå…¨é‡â€
				forceFull := (updateType == quarterUpdateType)
				success := u.rateLimitedUpdate(ctx, sym, timeframe, forceFull)
				results <- success
				if !success {
					failedMu.Lock()
					failedSymbols = append(failedSymbols, sym)
					failedMu.Unlock()
				}
			}()
		}
	}

	wg.Wait()
	close(results)

	successCount, failureCount := 0, 0
	for r := range results {
		if r {
			successCount++
		} else {
			failureCount++
		}
	}

	elapsed := time.Since(start)

	// æ›´æ–°ç»Ÿè®¡
	u.stats.Lock()
	u.stats.successCount = successCount
	u.stats.failureCount = failureCount
	// åªåœ¨å¸¸è§„å®šæ—¶æ›´æ–°æ—¶æ›´æ–° lastUpdateï¼Œé¿å…åˆå§‹åŒ–å’Œç´§æ€¥/quarter æ›´æ–°å¹²æ‰°æ—¶é—´è®°å½•
	if updateType == "regular" {
		u.stats.lastUpdate = time.Now().In(cst)
	}
	u.stats.Unlock()

	// æ›´æ–°ç³»ç»ŸçŠ¶æ€
	avgFreshness := u.redisClient.CalculateAverageFreshness(ctx, u.config.Symbols, timeframe)
	status := &redisClient.SystemStatus{
		Timeframe:         timeframe,
		LastFullScan:      time.Now().In(cst).Format(TimeFormat),
		ActiveSymbols:     len(u.config.Symbols),
		SuccessfulUpdates: successCount,
		FailedUpdates:     failureCount,
		UpdateDuration:    elapsed.Seconds(),
		DataFreshnessAvg:  avgFreshness,
	}
	if err := u.redisClient.UpdateSystemStatus(ctx, timeframe, status); err != nil {
		logrus.Warnf("[%s] UpdateSystemStatus error: %v", timeframe, err)
	}

	if len(failedSymbols) > 0 {
		logrus.Warnf("[%s] Failed symbols: %v", timeframe, failedSymbols[:min(len(failedSymbols), 10)])
		if len(failedSymbols) > 10 {
			logrus.Warnf("[%s] ... and %d more", timeframe, len(failedSymbols)-10)
		}
	}

	return successCount, failureCount, nil
}

// NOTE: æ–°ç­¾åï¼Œæ”¯æŒå¼ºåˆ¶å…¨é‡
func (u *DataUpdater) rateLimitedUpdate(ctx context.Context, symbol, timeframe string, forceFull bool) bool {
	// å¹¶å‘ä¿¡å·é‡
	select {
	case <-u.semaphore:
		defer func() { u.semaphore <- struct{}{} }()
	case <-ctx.Done():
		return false
	}

	// é€Ÿç‡é™åˆ¶
	if err := u.rateLimiter.Wait(ctx); err != nil {
		logrus.Errorf("%s [%s]: rate limit error: %v", symbol, timeframe, err)
		return false
	}

	return u.fetchAndStoreData(ctx, symbol, timeframe, forceFull, 3)
}

func (u *DataUpdater) fetchAndStoreData(ctx context.Context, symbol, timeframe string, forceFull bool, maxRetries int) bool {
	for attempt := 1; attempt <= maxRetries; attempt++ {
		existing, err := u.getExistingData(ctx, symbol, timeframe)
		if err != nil {
			logrus.Warnf("%s [%s]: read existing data error: %v", symbol, timeframe, err)
		}

		if err := u.doFetchAndStore(ctx, symbol, timeframe, forceFull, existing); err != nil {
			logrus.Warnf("%s [%s]: attempt %d/%d failed: %v", symbol, timeframe, attempt, maxRetries, err)
			if attempt < maxRetries {
				time.Sleep(time.Duration(attempt) * time.Second)
				continue
			}
			return false
		}
		return true
	}
	return false
}

func (u *DataUpdater) doFetchAndStore(ctx context.Context, symbol, timeframe string, forceFull bool, existing *redisClient.KlineData) error {
	interval := binance.ParseInterval(timeframe)

	if existing == nil || existing.CandleCount == 0 || existing.LastCandleTime == "" {
		logrus.Infof("ğŸ† Init    | %s [%s] fetching initial candles", symbol, timeframe)
		return u.doInitialFetch(ctx, symbol, timeframe)
	}

	// åˆ†æ¡£å®¹é‡ï¼šå†³å®šæ˜¯å¦éœ€è¦è¡¥é½ï¼ˆæ­¤å¤„ä»…åšæç¤ºï¼Œä¸è§¦å‘ FIFOï¼Œä¿ç•™ä¸º full åˆ¤æ–­ä¾æ®ï¼‰
	if cap := capacityForInterval(interval); existing.CandleCount < cap && !forceFull {
		logrus.Infof("ğŸ”„ Refill  | %s [%s] %d/%d refilling...", symbol, timeframe, existing.CandleCount, cap)
		return u.doFullUpdate(ctx, symbol, timeframe)
	}

	// å¼ºåˆ¶å…¨é‡
	if forceFull {
		logrus.Infof("ğŸŸ£ Force   | %s [%s] quarter tick -> FULL update", symbol, timeframe)
		return u.doFullUpdate(ctx, symbol, timeframe)
	}

	// æ­£å¸¸å¢é‡è·¯å¾„
	if u.canDoIncrementalUpdate(existing) {
		logrus.Infof("âš¡ Incr    | %s [%s] %d candles (last=%s)", symbol, timeframe, existing.CandleCount, existing.LastCandleTime)
		if err := u.doIncrementalUpdate(ctx, symbol, timeframe, existing); err == nil {
			logrus.Infof("âœ… Incr    | %s [%s] ok", symbol, timeframe)
			return nil
		} else {
			logrus.Warnf("âŒ Incr    | %s [%s] %v -> fallback to full", symbol, timeframe, err)
		}
	} else {
		logrus.Infof("ğŸ“‹ Status  | %s [%s] cannot do incremental (candles=%d,last=%s)", symbol, timeframe, existing.CandleCount, existing.LastCandleTime)
	}

	return u.doFullUpdate(ctx, symbol, timeframe)
}

func (u *DataUpdater) canDoIncrementalUpdate(existing *redisClient.KlineData) bool {
	if existing == nil || existing.LastCandleTime == "" {
		return false
	}
	if existing.CandleCount < 1 {
		return false
	}
	_, err := time.Parse(TimeFormat, existing.LastCandleTime)
	return err == nil
}

func (u *DataUpdater) doIncrementalUpdate(ctx context.Context, symbol, timeframe string, existing *redisClient.KlineData) error {
	if existing == nil || existing.LastCandleTime == "" {
		return fmt.Errorf("missing existing candle metadata")
	}

	lastCandleTime, err := time.ParseInLocation(TimeFormat, existing.LastCandleTime, cst)
	if err != nil {
		return fmt.Errorf("invalid last candle time: %w", err)
	}

	interval := binance.ParseInterval(timeframe)
	if interval <= 0 {
		return fmt.Errorf("unsupported timeframe %s", timeframe)
	}

	now := time.Now().In(cst)
	lastClosed := lastClosedBoundary(now, interval)

	// æ²¡æœ‰æ–°â€œå·²æ”¶ç›˜â€
	if !lastClosed.After(lastCandleTime) {
		logrus.Debugf("â° Wait    | %s [%s] no closed new candle (last=%s, closed=%s)", symbol, timeframe, lastCandleTime.Format(TimeFormat), lastClosed.Format(TimeFormat))
		return nil
	}

	// ä»ä¸‹ä¸€æ ¹å¼€ç›˜å¼€å§‹æ‹‰
	start := lastCandleTime.Add(interval).UTC()
	limit := 200
	if interval >= time.Hour {
		limit = 500
	}

	klines, err := u.binanceClient.GetKlines(ctx, symbol, timeframe, limit, &start, nil)
	if err != nil {
		return fmt.Errorf("fetch incremental klines error: %w", err)
	}
	if len(klines) == 0 {
		logrus.Debugf("âš ï¸  No-op   | %s [%s] no klines returned from %s", symbol, timeframe, start.In(cst).Format(TimeFormat))
		return nil
	}

	// ä»…ä¿ç•™â€œå·²æ”¶ç›˜â€çš„æ–°æ ¹
	var newKlines []binance.KlineItem
	for _, k := range klines {
		kt := time.UnixMilli(k.OpenTime).In(cst)
		if kt.After(lastCandleTime) && !kt.After(lastClosed) {
			newKlines = append(newKlines, k)
		}
	}
	if len(newKlines) == 0 {
		logrus.Debugf("âš ï¸  No-op   | %s [%s] no closed candles after %s", symbol, timeframe, lastCandleTime.Format(TimeFormat))
		return nil
	}

	// æ—¥çº¿å¢é‡ï¼šä¸è¶³ 10 æ ¹ â†’ ç›´æ¥å…¨é‡ï¼ˆä¸€æ¬¡ 30 æ ¹æ›´åˆç®—ï¼‰
	if interval >= 24*time.Hour && len(newKlines) < 10 {
		logrus.Infof("ğŸŸ¨ IncrSkip| %s [%s] closed=%d < 10, fallback to FULL", symbol, timeframe, len(newKlines))
		return u.doFullUpdate(ctx, symbol, timeframe)
	}

	// æ‰¹é‡å¢é‡ï¼ˆä¸åš FIFO å‰ªè£ï¼‰
	if err := u.storeKlineDataIncrementalBatch(ctx, symbol, timeframe, newKlines, existing); err != nil {
		return fmt.Errorf("store incremental error: %w", err)
	}

	latest := time.UnixMilli(newKlines[len(newKlines)-1].OpenTime).In(cst)
	logrus.Infof("ğŸ† New     | %s [%s] +%d (last=%s)", symbol, timeframe, len(newKlines), latest.Format(TimeFormat))
	return nil
}

// ---------- åˆ†æ¡£ç­–ç•¥ ----------

// åˆ†æ¡£ç›®æ ‡ï¼ˆç”¨äº Completeness çš„åˆ†æ¯æç¤ºï¼›ä¸å†ç”¨äº FIFO è£å‰ªï¼‰
// 1d=30, 4h=180, 1h=720ï¼›å…¶å®ƒå‘¨æœŸè¿”å› 0 è¡¨ç¤ºä¸åˆ†æ¡£
func targetForInterval(interval time.Duration) (targetCandles int, targetDays int) {
	switch interval {
	case 24 * time.Hour: // 1d
		return 30, 30
	case 4 * time.Hour: // 4h
		return 180, 30
	case time.Hour: // 1h
		return 720, 30
	default:
		return 0, 0
	}
}

// åˆ†æ¡£å®¹é‡ï¼ˆä¿ç•™ç»™æ—¥å¿—æç¤º/å›å¡«åˆ¤æ–­ï¼Œä¸ç”¨äºå®é™…è£å‰ªï¼‰
func capacityForInterval(interval time.Duration) int {
	if tgt, _ := targetForInterval(interval); tgt > 0 {
		return tgt
	}
	return maxStoredCandles
}

// ---------- æ•°æ®æ‹‰å–/å­˜å‚¨ ----------

func (u *DataUpdater) doInitialFetch(ctx context.Context, symbol, timeframe string) error {
	// åˆæ¬¡æ‹‰å–æŒ‰åˆ†æ¡£å®¹é‡é™æµï¼Œé¿å…ä¸€æ¬¡æ‹¿ 1000 æ ¹å¯¹ 1d é€ æˆæµªè´¹
	capacity := capacityForInterval(binance.ParseInterval(timeframe))
	limit := initialKlineCount
	if capacity > 0 && capacity < limit {
		limit = capacity
	}

	klines, err := u.binanceClient.GetKlines(ctx, symbol, timeframe, limit, nil, nil)
	if err != nil {
		return fmt.Errorf("failed to fetch initial klines: %w", err)
	}
	if len(klines) == 0 {
		return fmt.Errorf("no initial kline data received")
	}
	if err := u.storeKlineData(symbol, timeframe, klines, nil, false, ctx); err != nil {
		return fmt.Errorf("failed to store initial data: %w", err)
	}
	logrus.Infof("âœ… Init    | %s [%s] loaded %d candles", symbol, timeframe, len(klines))
	return nil
}

func (u *DataUpdater) doFullUpdate(ctx context.Context, symbol, timeframe string) error {
	interval := binance.ParseInterval(timeframe)

	// åˆ†æ¡£ï¼š1d=30, 4h=180, 1h=720 â†’ ä¼˜å…ˆ 30 å¤©è¦†ç›–
	targetCandles, targetDays := targetForInterval(interval)

	var dayOptions []int
	if targetDays > 0 {
		dayOptions = []int{max(u.config.DataDays, targetDays), 60, 45, 30, 15, 7}
	} else {
		dayOptions = []int{u.config.DataDays, 30, 15, 7}
	}

	for _, days := range dayOptions {
		if days <= 0 {
			continue
		}
		logrus.Debugf("%s [%s]: Attempting to fetch %d days of historical data", symbol, timeframe, days)

		klines, err := u.binanceClient.GetHistoricalData(ctx, symbol, timeframe, days)
		if err != nil {
			logrus.Warnf("%s [%s]: Failed to fetch %d days of data: %v", symbol, timeframe, days, err)
			continue
		}

		if len(klines) >= 10 {
			if err := u.storeKlineData(symbol, timeframe, klines, nil, false, ctx); err != nil {
				return fmt.Errorf("failed to store data: %w", err)
			}
			if targetCandles > 0 {
				logrus.Infof("âœ… Full    | %s [%s] %d candles from %d days (target=%d)", symbol, timeframe, len(klines), days, targetCandles)
			} else {
				logrus.Infof("âœ… Full    | %s [%s] %d candles from %d days", symbol, timeframe, len(klines))
			}
			return nil
		}

		logrus.Warnf("%s [%s]: Insufficient data for %d days: %d candles", symbol, timeframe, days, len(klines))
	}

	return fmt.Errorf("failed to fetch sufficient data with all day options")
}

func (u *DataUpdater) getExistingData(ctx context.Context, symbol, timeframe string) (*redisClient.KlineData, error) {
	data, err := u.redisClient.GetKlineData(ctx, symbol, timeframe)
	if err != nil {
		return nil, err
	}
	if data == nil {
		return nil, nil
	}
	if data.CandleCount == 0 && data.OHLCVData == "" {
		return nil, nil
	}
	return data, nil
}

// storeKlineDataï¼šåˆå§‹/å…¨é‡å†™å…¥ï¼›**ä¸åš FIFO è£å‰ª**
func (u *DataUpdater) storeKlineData(symbol, timeframe string, klines []binance.KlineItem, existing *redisClient.KlineData, merge bool, ctx context.Context) error {
	if len(klines) == 0 {
		return fmt.Errorf("no kline data to store")
	}
	combined := make(map[string]map[string]string)

	if merge && existing != nil && existing.OHLCVData != "" {
		var existingMap map[string]interface{}
		if err := json.Unmarshal([]byte(existing.OHLCVData), &existingMap); err != nil {
			logrus.Warnf("%s [%s]: unmarshal existing error: %v", symbol, timeframe, err)
		} else {
			for ts, raw := range existingMap {
				switch m := raw.(type) {
				case map[string]interface{}:
					row := make(map[string]string, len(m))
					for k, v := range m {
						row[k] = fmt.Sprintf("%v", v)
					}
					combined[ts] = row
				case map[string]string:
					combined[ts] = m
				}
			}
		}
	}

	for _, kline := range klines {
		key := time.UnixMilli(kline.OpenTime).In(cst).Format(TimeFormat)
		combined[key] = map[string]string{
			"open":      kline.Open.String(),
			"high":      kline.High.String(),
			"low":       kline.Low.String(),
			"close":     kline.Close.String(),
			"volume":    kline.Volume.String(),
			"timestamp": strconv.FormatInt(kline.OpenTime, 10),
		}
	}

	return u.persistCleaned(ctx, symbol, timeframe, combined, existing)
}

// å•æ ¹å¢é‡ï¼ˆå†…éƒ¨è½¬æ‰¹é‡ï¼‰
func (u *DataUpdater) storeKlineDataIncremental(ctx context.Context, symbol, timeframe string, newKline binance.KlineItem, existing *redisClient.KlineData) error {
	return u.storeKlineDataIncrementalBatch(ctx, symbol, timeframe, []binance.KlineItem{newKline}, existing)
}

// æ‰¹é‡å¢é‡ï¼ˆ**ä¸åš FIFO å‰ªè£**ï¼‰
func (u *DataUpdater) storeKlineDataIncrementalBatch(ctx context.Context, symbol, timeframe string, newKlines []binance.KlineItem, existing *redisClient.KlineData) error {
	existingMap := make(map[string]map[string]string)
	if existing != nil && existing.OHLCVData != "" {
		var raw map[string]interface{}
		if err := json.Unmarshal([]byte(existing.OHLCVData), &raw); err != nil {
			return fmt.Errorf("unmarshal existing OHLCV error: %w", err)
		}
		for ts, v := range raw {
			switch vv := v.(type) {
			case map[string]interface{}:
				row := make(map[string]string, len(vv))
				for k, val := range vv {
					row[k] = fmt.Sprintf("%v", val)
				}
				existingMap[ts] = row
			case map[string]string:
				existingMap[ts] = vv
			}
		}
	}

	for _, nk := range newKlines {
		key := time.UnixMilli(nk.OpenTime).In(cst).Format(TimeFormat)
		existingMap[key] = map[string]string{
			"open":      nk.Open.String(),
			"high":      nk.High.String(),
			"low":       nk.Low.String(),
			"close":     nk.Close.String(),
			"volume":    nk.Volume.String(),
			"timestamp": strconv.FormatInt(nk.OpenTime, 10),
		}
	}

	return u.persistCleaned(ctx, symbol, timeframe, existingMap, existing)
}

// æ¸…æ´—+åºåˆ—åŒ–+å†™å…¥ï¼ˆ**æ—  FIFO**ï¼‰ï¼ŒæŒ‰â€œå·²æ”¶ç›˜â€è¿‡æ»¤
func (u *DataUpdater) persistCleaned(ctx context.Context, symbol, timeframe string, data map[string]map[string]string, existing *redisClient.KlineData) error {
	if len(data) == 0 {
		return fmt.Errorf("no data to persist")
	}

	interval := u.resolveInterval(timeframe)
	now := time.Now().In(cst)
	lastClosed := lastClosedBoundary(now, interval)

	// è¿‡æ»¤æœªæ¥/æœªæ”¶ç›˜
	timestamps := make([]time.Time, 0, len(data))
	clean := make(map[string]map[string]string, len(data))
	for ts, row := range data {
		t, err := time.ParseInLocation(TimeFormat, ts, cst)
		if err != nil {
			logrus.Warnf("%s [%s]: invalid time %s: %v", symbol, timeframe, ts, err)
			continue
		}
		if t.After(lastClosed) {
			continue
		}
		key := t.In(cst).Format(TimeFormat)
		clean[key] = row
		timestamps = append(timestamps, t.In(cst))
	}
	if len(timestamps) == 0 {
		return fmt.Errorf("no valid timestamps after clamping")
	}

	sort.Slice(timestamps, func(i, j int) bool { return timestamps[i].Before(timestamps[j]) })

	startTime := timestamps[0]
	endTime := timestamps[len(timestamps)-1]

	// åºåˆ—åŒ–
	ohlcvMap := make(map[string]interface{}, len(clean))
	for ts, values := range clean {
		ohlcvMap[ts] = values
	}
	ohlcvData, err := json.Marshal(ohlcvMap)
	if err != nil {
		return fmt.Errorf("marshal OHLCV error: %w", err)
	}

	// å†…å®¹æœªå˜ â†’ è·³è¿‡å†™å…¥
	if existing != nil && existing.OHLCVData == string(ohlcvData) {
		logrus.Debugf("ğŸŸ¡ Skip    | %s [%s] ohlcv unchanged (%d candles), last=%s", symbol, timeframe, len(clean), endTime.Format(TimeFormat))
		return nil
	}

	// Completenessï¼šä¸åšå®¹é‡ clampï¼›å¦‚æœæœ‰åˆ†æ¡£ç›®æ ‡ï¼Œç”¨ç›®æ ‡ä½œåˆ†æ¯ï¼Œå¦åˆ™ç”¨å½“å‰æ¡æ•°
	targetCandles, _ := targetForInterval(interval)
	expectedCandles := len(clean)
	if targetCandles > 0 && targetCandles > expectedCandles {
		expectedCandles = targetCandles
	}
	completeness := 1.0
	if expectedCandles > 0 {
		completeness = float64(len(clean)) / float64(expectedCandles)
		if completeness > 1 {
			completeness = 1
		}
	}

	klineData := &redisClient.KlineData{
		OHLCVData:      string(ohlcvData),
		LastCandleTime: endTime.In(cst).Format(TimeFormat),
		LastUpdate:     now.Format(TimeFormat),
		DataStart:      startTime.In(cst).Format(TimeFormat),
		DataEnd:        endTime.In(cst).Format(TimeFormat),
		Completeness:   completeness,
		CandleCount:    len(clean),
		Timeframe:      timeframe,
		DataAgeSeconds: now.Sub(endTime).Seconds(),
	}

	// å†™å…¥åŠ  5s è¶…æ—¶ï¼Œé¿å…å¡æ­»
	writeCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()
	return u.redisClient.StoreKlineData(writeCtx, symbol, timeframe, klineData)
}

// ---------- Quarter-hour è°ƒåº¦ï¼ˆå…¨é‡åˆ·æ–°ï¼‰ ----------

// åˆ°ä¸‹ä¸€ä¸ª 0/15/30/45 çš„å»¶æ—¶ï¼›é¢å¤–åŠ  5 ç§’ä¿è¯äº¤æ˜“æ‰€æ•°æ®å¯è¯»
func timeUntilNextQuarterMark(now time.Time) time.Duration {
	q := 15 * time.Minute
	next := now.Truncate(q).Add(q)
	delay := next.Sub(now)
	if delay <= 0 {
		delay = q
	}
	return delay + 5*time.Second
}

// ç»Ÿä¸€çš„ quarter æ ‡ç­¾
const quarterUpdateType = "quarter"

// æ¯é€¢ 0/15/30/45 åˆ†ï¼Œå¯¹æ‰€æœ‰ timeframe + æ‰€æœ‰ symbol å¼ºåˆ¶è·‘â€œå…¨é‡â€å†™å…¥
func (u *DataUpdater) runQuarterHourlyLoop(ctx context.Context) error {
	firstDelay := timeUntilNextQuarterMark(time.Now().In(cst))
	logrus.Infof("â±ï¸  [Quarter] first tick in %s (aligned to :00/:15/:30/:45)", firstDelay.Truncate(time.Millisecond))
	timer := time.NewTimer(firstDelay)
	defer timer.Stop()

	for {
		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-timer.C:
			start := time.Now()
			logrus.Infof("ğŸ§­ Quarter | launching FULL refresh for all timeframes (%v)", u.timeframes)

			// å¹¶å‘ï¼šä»¥ timeframe ä¸ºå•ä½å¹¶å‘ï¼›å†…éƒ¨ä¾æ—§éµå®ˆ limiter/semaphore
			var wg sync.WaitGroup
			successTotal, failedTotal := 0, 0
			var mu sync.Mutex

			for _, tf := range u.timeframes {
				tfLocal := tf
				wg.Add(1)
				go func() {
					defer wg.Done()
					// è¿™é‡Œä¼ å…¥ updateType=quarterï¼Œå†…éƒ¨èµ° forceFull=true
					success, failed, err := u.updateAllSymbolsForTimeframeWithType(ctx, tfLocal, quarterUpdateType)
					mu.Lock()
					successTotal += success
					failedTotal += failed
					mu.Unlock()
					if err != nil {
						logrus.Errorf("âŒ Quarter | [%s] %v", tfLocal, err)
					} else {
						logrus.Infof("âœ… Quarter | [%s] ok (âœ…%d âŒ%d)", tfLocal, success, failed)
					}
				}()
			}
			wg.Wait()

			logrus.Infof("ğŸ§­ Quarter | done in %.1fs (âœ…%d âŒ%d)", time.Since(start).Seconds(), successTotal, failedTotal)

			nextDelay := timeUntilNextQuarterMark(time.Now().In(cst))
			timer.Reset(nextDelay)
		}
	}
}

// ---------- å…¶å®ƒ ----------

func (u *DataUpdater) checkStaleData(ctx context.Context, timeframe string) ([]string, error) {
	return u.redisClient.CheckDataFreshness(ctx, u.config.Symbols, timeframe, u.config.MaxDataAge)
}

func (u *DataUpdater) urgentUpdate(ctx context.Context, timeframe string, symbols []string) {
	if len(symbols) == 0 {
		return
	}
	logrus.Infof("[%s] urgent update: %v", timeframe, symbols)

	var wg sync.WaitGroup
	for _, symbol := range symbols {
		wg.Add(1)
		go func(sym string) {
			defer wg.Done()
			u.rateLimitedUpdate(ctx, sym, timeframe, false)
		}(symbol)
	}
	wg.Wait()
}

func (u *DataUpdater) calculateOptimalInterval(currentInterval, minInterval time.Duration) time.Duration {
	currentHour := time.Now().In(cst).Hour()
	peakHours := []int{7, 8, 9, 13, 14, 15, 21, 22}
	isPeak := false
	for _, h := range peakHours {
		if currentHour == h {
			isPeak = true
			break
		}
	}

	base := currentInterval
	if base <= 0 {
		base = minInterval
	}

	if u.config.MarketHoursOptimization && !isPeak {
		base = time.Duration(float64(base) * u.config.OffPeakMultiplier)
	}

	u.stats.RLock()
	errRate := float64(u.stats.failureCount) / float64(u.stats.successCount+u.stats.failureCount)
	u.stats.RUnlock()

	if errRate > 0.2 {
		base = time.Duration(float64(base) * u.config.ErrorBackoffMultiplier)
	} else if errRate < 0.05 {
		base = time.Duration(float64(base) * u.config.SuccessRecoveryRate)
	}

	// clamp åˆ° [minInterval, 4*minInterval]
	if base < minInterval {
		base = minInterval
	}
	maxInt := 4 * minInterval
	if base > maxInt {
		base = maxInt
	}
	return base
}

func (u *DataUpdater) resolveInterval(timeframe string) time.Duration {
	interval := binance.ParseInterval(timeframe)
	if interval <= 0 {
		interval = time.Minute
	}
	return interval
}

// timeUntilNextKlineClose è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªKçº¿æ”¶ç›˜æ—¶é—´çš„å»¶è¿Ÿ
// Kçº¿æ”¶ç›˜æ—¶é—´å°±æ˜¯ä¸‹ä¸€ä¸ªKçº¿çš„å¼€ç›˜æ—¶é—´ï¼Œå†åŠ 5ç§’å»¶è¿Ÿç¡®ä¿æ•°æ®å¯ç”¨
func timeUntilNextKlineClose(interval time.Duration) time.Duration {
	return timeUntilNextBoundary(interval) + 5*time.Second
}

func timeUntilNextBoundary(interval time.Duration) time.Duration {
	if interval <= 0 {
		return time.Second
	}
	now := time.Now().In(cst)
	var next time.Time

	switch interval {
	case time.Minute:
		next = now.Truncate(time.Minute).Add(time.Minute)
	case 3 * time.Minute:
		m := now.Minute()
		nm := ((m / 3) + 1) * 3
		if nm >= 60 {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour()+1, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour(), nm, 0, 0, now.Location())
		}
	case 5 * time.Minute:
		m := now.Minute()
		nm := ((m / 5) + 1) * 5
		if nm >= 60 {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour()+1, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour(), nm, 0, 0, now.Location())
		}
	case 15 * time.Minute:
		m := now.Minute()
		nm := ((m / 15) + 1) * 15
		if nm >= 60 {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour()+1, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour(), nm, 0, 0, now.Location())
		}
	case 30 * time.Minute:
		m := now.Minute()
		if m < 30 {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour(), 30, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour()+1, 0, 0, 0, now.Location())
		}
	case time.Hour:
		next = time.Date(now.Year(), now.Month(), now.Day(), now.Hour()+1, 0, 0, 0, now.Location())
	case 2 * time.Hour:
		h := now.Hour()
		nh := ((h / 2) + 1) * 2
		if nh >= 24 {
			next = time.Date(now.Year(), now.Month(), now.Day()+1, 0, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), nh, 0, 0, 0, now.Location())
		}
	case 4 * time.Hour:
		h := now.Hour()
		nh := ((h / 4) + 1) * 4
		if nh >= 24 {
			next = time.Date(now.Year(), now.Month(), now.Day()+1, 0, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), nh, 0, 0, 0, now.Location())
		}
	case 6 * time.Hour:
		h := now.Hour()
		nh := ((h / 6) + 1) * 6
		if nh >= 24 {
			next = time.Date(now.Year(), now.Month(), now.Day()+1, 0, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), nh, 0, 0, 0, now.Location())
		}
	case 8 * time.Hour:
		h := now.Hour()
		nh := ((h / 8) + 1) * 8
		if nh >= 24 {
			next = time.Date(now.Year(), now.Month(), now.Day()+1, 0, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day(), nh, 0, 0, 0, now.Location())
		}
	case 12 * time.Hour:
		h := now.Hour()
		if h < 12 {
			next = time.Date(now.Year(), now.Month(), now.Day(), 12, 0, 0, 0, now.Location())
		} else {
			next = time.Date(now.Year(), now.Month(), now.Day()+1, 0, 0, 0, 0, now.Location())
		}
	case 24 * time.Hour:
		next = time.Date(now.Year(), now.Month(), now.Day()+1, 0, 0, 0, 0, now.Location())
	default:
		next = now.Truncate(interval).Add(interval)
	}

	delay := next.Sub(now)
	if delay <= 0 {
		delay = interval
	}
	return delay
}

func lastClosedBoundary(now time.Time, interval time.Duration) time.Time {
	return now.Truncate(interval)
}

func (u *DataUpdater) GetResourceUsage() ResourceUsage {
	symbolCount := len(u.config.Symbols)
	totalCallsPerHour := 0.0
	for _, timeframe := range u.timeframes {
		interval := u.resolveInterval(timeframe)
		if interval <= 0 {
			continue
		}
		totalCallsPerHour += (3600.0 / interval.Seconds()) * float64(symbolCount)
	}
	estimatedMemory := symbolCount * len(u.timeframes) * 2
	if estimatedMemory == 0 {
		estimatedMemory = symbolCount * 2
	}
	return ResourceUsage{
		APICallsPerHour:    totalCallsPerHour,
		EstimatedMemoryMB:  estimatedMemory,
		BandwidthPerHourMB: (totalCallsPerHour * 10) / 1024,
	}
}

func (u *DataUpdater) HealthCheck(ctx context.Context) error {
	if err := u.redisClient.Ping(ctx); err != nil {
		return fmt.Errorf("redis health check failed: %w", err)
	}
	if err := u.binanceClient.TestConnectivity(ctx); err != nil {
		return fmt.Errorf("binance health check failed: %w", err)
	}
	if len(u.config.Symbols) > 0 {
		valid, err := u.binanceClient.ValidateSymbol(ctx, u.config.Symbols[0])
		if err != nil {
			return fmt.Errorf("symbol validation failed: %w", err)
		}
		if !valid {
			return fmt.Errorf("test symbol %s is not valid", u.config.Symbols[0])
		}
	}
	logrus.Info("Health check passed")
	return nil
}

func (u *DataUpdater) Close() error {
	u.mu.Lock()
	u.isRunning = false
	u.mu.Unlock()
	return u.redisClient.Close()
}

// Expose internal clients for fused services
func (u *DataUpdater) Redis() *redisClient.Client { return u.redisClient }
func (u *DataUpdater) Binance() *binance.Client { return u.binanceClient }

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func max(a, b int) int {
	if a > b {
		return a
	}
	return b
}

// startCountdownDisplay å¯åŠ¨å€’è®¡æ—¶æ˜¾ç¤ºåç¨‹
func (u *DataUpdater) startCountdownDisplay(ctx context.Context) {
	ticker := time.NewTicker(10 * time.Second) // æ¯10ç§’æ›´æ–°ä¸€æ¬¡å€’è®¡æ—¶æ˜¾ç¤º
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			u.displayCountdowns()
		}
	}
}

// displayCountdowns æ˜¾ç¤ºæ‰€æœ‰æ—¶é—´å‘¨æœŸçš„å€’è®¡æ—¶
func (u *DataUpdater) displayCountdowns() {
	now := time.Now().In(cst)
	var countdownInfos []string

	// å…ˆæ˜¾ç¤ºå…¨å±€ Quarter åˆ·æ–°å€’è®¡æ—¶
	qDelay := timeUntilNextQuarterMark(now)
	countdownInfos = append(countdownInfos, formatCountdownDisplay("Quarter(å…¨å±€15m)", qDelay))

	for _, timeframe := range u.timeframes {
		// å®æ—¶è®¡ç®—ä¸‹æ¬¡æ›´æ–°æ—¶é—´ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å­˜å‚¨çš„æ—¶é—´
		interval := u.resolveInterval(timeframe)
		nextDelay := timeUntilNextKlineClose(interval)

		// æ ¼å¼åŒ–å•ä¸ªå€’è®¡æ—¶æ˜¾ç¤º
		formattedCountdown := formatCountdownDisplay(timeframe, nextDelay)
		countdownInfos = append(countdownInfos, formattedCountdown)
	}

	if len(countdownInfos) > 0 {
		// åˆ›å»ºç¾åŒ–çš„å€’è®¡æ—¶æ˜¾ç¤º
		currentTime := now.In(cst).Format("15:04:05")
		header := fmt.Sprintf("â° Kçº¿æ›´æ–°å€’è®¡æ—¶ - %s", currentTime)

		logrus.Infof("")
		logrus.Infof("â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®")
		logrus.Infof("â”‚ %-71s â”‚", header)
		logrus.Infof("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

		// æŒ‰è¡Œæ˜¾ç¤ºï¼Œæ¯è¡Œæœ€å¤š2ä¸ªæ—¶é—´å‘¨æœŸä»¥ç¡®ä¿å¯¹é½
		for i := 0; i < len(countdownInfos); i += 2 {
			end := i + 2
			if end > len(countdownInfos) {
				end = len(countdownInfos)
			}

			if end-i == 2 {
				// ä¸¤ä¸ªé¡¹ç›®çš„è¡Œ
				logrus.Infof("â”‚ %-34s â”‚ %-34s â”‚", countdownInfos[i], countdownInfos[end-1])
			} else {
				// å•ä¸ªé¡¹ç›®çš„è¡Œ
				logrus.Infof("â”‚ %-71s â”‚", countdownInfos[i])
			}
		}

		logrus.Infof("â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯")
		logrus.Infof("")
	}
}

// formatCountdownDisplay æ ¼å¼åŒ–å•ä¸ªå€’è®¡æ—¶æ˜¾ç¤ºï¼Œå¸¦é¢œè‰²å’Œç‰¹æ®Šç¬¦å·
func formatCountdownDisplay(timeframe string, remaining time.Duration) string {
	timeStr := formatDuration(remaining)

	// æ ¹æ®å‰©ä½™æ—¶é—´é€‰æ‹©ä¸åŒçš„å›¾æ ‡å’Œæ ·å¼
	var icon, status string
	totalSeconds := int(remaining.Seconds())

	switch {
	case totalSeconds <= 60: // 1åˆ†é’Ÿå†…
		icon = "ğŸ”¥"
		status = "å³å°†æ›´æ–°"
	case totalSeconds <= 300: // 5åˆ†é’Ÿå†…
		icon = "âš¡"
		status = "å‡†å¤‡ä¸­"
	case totalSeconds <= 1800: // 30åˆ†é’Ÿå†…
		icon = "ğŸ•"
		status = "ç­‰å¾…ä¸­"
	default:
		icon = "â±ï¸"
		status = "å¾…æœºä¸­"
	}

	// ç¾åŒ–æ—¶é—´å‘¨æœŸæ˜¾ç¤º
	var tfDisplay string
	switch timeframe {
	case "1m":
		tfDisplay = "1åˆ†é’Ÿ"
	case "5m":
		tfDisplay = "5åˆ†é’Ÿ"
	case "15m":
		tfDisplay = "15åˆ†é’Ÿ"
	case "30m":
		tfDisplay = "30åˆ†é’Ÿ"
	case "1h":
		tfDisplay = "1å°æ—¶"
	case "4h":
		tfDisplay = "4å°æ—¶"
	case "1d":
		tfDisplay = "1å¤©"
	default:
		tfDisplay = timeframe
	}

	return fmt.Sprintf("%s %s %s %s", icon, tfDisplay, timeStr, status)
}

// formatDuration æ ¼å¼åŒ–æ—¶é—´é—´éš”ä¸ºæ˜“è¯»æ ¼å¼
func formatDuration(d time.Duration) string {
	if d <= 0 {
		return "00:00"
	}

	totalSeconds := int(d.Seconds())
	hours := totalSeconds / 3600
	minutes := (totalSeconds % 3600) / 60
	seconds := totalSeconds % 60

	if hours > 0 {
		return fmt.Sprintf("%02d:%02d:%02d", hours, minutes, seconds)
	}
	return fmt.Sprintf("%02d:%02d", minutes, seconds)
}

// GetCountdowns è·å–æ‰€æœ‰æ—¶é—´å‘¨æœŸçš„å€’è®¡æ—¶ä¿¡æ¯
func (u *DataUpdater) GetCountdowns() map[string]string {
	result := make(map[string]string)

	// å…¨å±€ quarter
	result["quarter"] = formatDuration(timeUntilNextQuarterMark(time.Now().In(cst)))

	for _, timeframe := range u.timeframes {
		// å®æ—¶è®¡ç®—ä¸‹æ¬¡æ›´æ–°æ—¶é—´
		interval := u.resolveInterval(timeframe)
		nextDelay := timeUntilNextKlineClose(interval)
		result[timeframe] = formatDuration(nextDelay)
	}

	return result
}

func (u *DataUpdater) GetStats() map[string]interface{} {
	u.stats.RLock()
	defer u.stats.RUnlock()

	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)

	lastUpd := ""
	if !u.stats.lastUpdate.IsZero() {
		lastUpd = u.stats.lastUpdate.In(cst).Format(TimeFormat)
	}

	return map[string]interface{}{
		"success_count": u.stats.successCount,
		"failure_count": u.stats.failureCount,
		"last_update":   lastUpd,
		"memory_mb":     memStats.Alloc / 1024 / 1024,
		"goroutines":    runtime.NumGoroutine(),
		"is_running":    u.isRunning,
		"timeframes":    append([]string(nil), u.timeframes...),
		"countdowns":    u.GetCountdowns(),
	}
}
